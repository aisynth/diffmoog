{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os, glob\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "\n",
    "from torchaudio.functional.filtering import lowpass_biquad, highpass_biquad\n",
    "\n",
    "from torchaudio.transforms import Spectrogram, SpectralCentroid\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from model import helper\n",
    "from model.model import SimpleSynthNetwork\n",
    "from synth.synth_architecture import SynthModular\n",
    "from config import SynthConfig, Config\n",
    "from dataset.ai_synth_dataset import AiSynthDataset, create_data_loader\n",
    "\n",
    "from synth.synth_modular_chains import synth_chains_dict\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "spectrogram = Spectrogram(n_fft=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\fm_filter_dataset\\\\train\\\\params_dataset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m wav_files_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwav_files\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m params_csv_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams_dataset.pkl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 10\u001B[0m ai_synth_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mAiSynthDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_csv_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwav_files_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m test_dataloader \u001B[38;5;241m=\u001B[39m create_data_loader(ai_synth_dataset, \u001B[38;5;241m32\u001B[39m, \u001B[38;5;241m4\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ai_synth\\src\\dataset\\ai_synth_dataset.py:25\u001B[0m, in \u001B[0;36mAiSynthDataset.__init__\u001B[1;34m(self, parameters_pickle, audio_dir, device_arg)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m     22\u001B[0m              parameters_pickle,\n\u001B[0;32m     23\u001B[0m              audio_dir,\n\u001B[0;32m     24\u001B[0m              device_arg):\n\u001B[1;32m---> 25\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_pickle\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparameters_pickle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maudio_dir \u001B[38;5;241m=\u001B[39m audio_dir\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m device_arg\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001B[0m, in \u001B[0;36mread_pickle\u001B[1;34m(filepath_or_buffer, compression, storage_options)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03m4    4    9\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[0;32m    186\u001B[0m excs_to_catch \u001B[38;5;241m=\u001B[39m (\u001B[38;5;167;01mAttributeError\u001B[39;00m, \u001B[38;5;167;01mImportError\u001B[39;00m, \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m)\n\u001B[1;32m--> 187\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    194\u001B[0m \n\u001B[0;32m    195\u001B[0m     \u001B[38;5;66;03m# 1) try standard library Pickle\u001B[39;00m\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001B[39;00m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001B[39;00m\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    200\u001B[0m         \u001B[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001B[39;00m\n\u001B[0;32m    201\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:798\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    790\u001B[0m             handle,\n\u001B[0;32m    791\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    794\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    795\u001B[0m         )\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m--> 798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     handles\u001B[38;5;241m.\u001B[39mappend(handle)\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data\\\\fm_filter_dataset\\\\train\\\\params_dataset.pkl'"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "dataset_to_visualize = 'fm_filter_dataset'\n",
    "split_to_visualize = 'train'\n",
    "data_dir = os.path.join('data', dataset_to_visualize, split_to_visualize, '')\n",
    "\n",
    "wav_files_dir = os.path.join(data_dir, 'wav_files', '')\n",
    "params_csv_path = os.path.join(data_dir, 'params_dataset.pkl')\n",
    "\n",
    "ai_synth_dataset = AiSynthDataset(params_csv_path, wav_files_dir, device)\n",
    "test_dataloader = create_data_loader(ai_synth_dataset, 32, 4, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "synth_cfg = SynthConfig()\n",
    "cfg = Config()\n",
    "\n",
    "transform = helper.mel_spectrogram_transform(cfg.sample_rate).to(device)\n",
    "normalizer = helper.Normalizer(cfg.signal_duration_sec, synth_cfg)\n",
    "\n",
    "synth_obj = SynthModular(synth_cfg=synth_cfg,\n",
    "                         sample_rate=cfg.sample_rate,\n",
    "                         signal_duration_sec=cfg.signal_duration_sec,\n",
    "                         num_sounds=1,\n",
    "                         device=device,\n",
    "                         chain='FM_FILTER')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "SimpleSynthNetwork(\n  (backbone): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=128, bias=True)\n  )\n  (heads_module_dict): ModuleDict(\n    ((0, 2)_filter_filter_type): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=2, bias=False)\n      )\n    )\n    ((0, 2)_filter_filter_freq): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=1, bias=False)\n      )\n    )\n  )\n  (softmax): Softmax(dim=1)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfo_model_ckpt = r'E:\\Users\\elhara2\\ai_synth\\experiments\\current\\lfo_only_model_fm_filter_data\\ckpts\\trained_synth_net.pt'\n",
    "fm_model_ckpt = r'E:\\Users\\elhara2\\ai_synth\\experiments\\current\\fm_only_model_fm_filter_data_2\\ckpts\\trained_synth_net.pt'\n",
    "filter_model_ckpt = r'E:\\Users\\elhara2\\ai_synth\\experiments\\current\\filter_only_model_fm_filter_data\\ckpts\\trained_synth_net.pt'\n",
    "\n",
    "lfo_model = SimpleSynthNetwork('LFO', synth_cfg, device, backbone='resnet').to(device)\n",
    "fm_model = SimpleSynthNetwork('FM_ONLY', synth_cfg, device, backbone='resnet').to(device)\n",
    "filter_model = SimpleSynthNetwork('FILTER_ONLY', synth_cfg, device, backbone='resnet').to(device)\n",
    "\n",
    "lfo_model.load_state_dict(torch.load(lfo_model_ckpt))\n",
    "fm_model.load_state_dict(torch.load(fm_model_ckpt))\n",
    "filter_model.load_state_dict(torch.load(filter_model_ckpt))\n",
    "\n",
    "lfo_model.eval()\n",
    "fm_model.eval()\n",
    "filter_model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def discretize_params(operation: str, input_params: dict, synth_cfg):\n",
    "\n",
    "    params_chain = synth_cfg.all_params_chains.get(operation, {})\n",
    "\n",
    "    res = {}\n",
    "    for param_name, param_values in input_params.items():\n",
    "\n",
    "        if isinstance(param_values, torch.Tensor):\n",
    "            param_values = param_values.detach().cpu().numpy()\n",
    "        else:\n",
    "            param_values = np.asarray(param_values)\n",
    "\n",
    "        if param_name in ['waveform', 'filter_type']:\n",
    "\n",
    "            if isinstance(param_values[0], str):\n",
    "                res[param_name] = param_values\n",
    "                continue\n",
    "\n",
    "            idx = np.argmax(param_values, axis=1)\n",
    "            if param_name == 'waveform':\n",
    "                res[param_name] = [synth_cfg.wave_type_dic_inv[i] for i in idx]\n",
    "            else:\n",
    "                res[param_name] = [synth_cfg.filter_type_dic_inv[i] for i in idx]\n",
    "            continue\n",
    "\n",
    "        possible_values = params_chain.get(param_name, None)\n",
    "\n",
    "        if possible_values is None:\n",
    "            res[param_name] = param_values\n",
    "            continue\n",
    "\n",
    "        idx = np.searchsorted(possible_values, param_values, side=\"left\")\n",
    "        idx[idx == len(possible_values)] = len(possible_values) - 1\n",
    "        idx[idx == 0] = 1\n",
    "\n",
    "        if operation == 'fm' and param_name == 'freq_c':\n",
    "            below_distance = (param_values / possible_values[idx - 1])\n",
    "            above_distance = (possible_values[idx] / param_values)\n",
    "        else:\n",
    "            below_distance = np.abs(param_values - possible_values[idx - 1])\n",
    "            above_distance = np.abs(param_values - possible_values[idx])\n",
    "\n",
    "        idx = idx - (below_distance < above_distance)\n",
    "        res[param_name] = possible_values[idx]\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def compare_params(target_params, predicted_params):\n",
    "    res = defaultdict(dict)\n",
    "    for cell_idx, target_cell_data in target_params.items():\n",
    "\n",
    "        if target_cell_data['operation'][0] == 'None':\n",
    "            continue\n",
    "\n",
    "        target_cell_params = target_cell_data['parameters']\n",
    "        predicted_cell_params = predicted_params[cell_idx]['parameters']\n",
    "\n",
    "        for param_name, target_param_values in target_cell_params.items():\n",
    "            pred_param_values = np.asarray(predicted_cell_params[param_name]).squeeze()\n",
    "            target_param_values = np.asarray(target_param_values).squeeze()\n",
    "\n",
    "            assert len(target_param_values) == len(pred_param_values)\n",
    "\n",
    "            correct_preds = np.sum(target_param_values == pred_param_values)\n",
    "\n",
    "            res[cell_idx][param_name] = correct_preds\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "step, n_samples = 0, 0\n",
    "results = defaultdict(int)\n",
    "for target_signal, target_param_dict, signal_index in test_dataloader:\n",
    "\n",
    "    step += 1\n",
    "\n",
    "    target_signal = target_signal.to(device)\n",
    "    transformed_signal = transform(target_signal)\n",
    "\n",
    "    # -----------Run Model-----------------\n",
    "    output_lfo_params = lfo_model(transformed_signal)\n",
    "    output_fm_params = fm_model(transformed_signal)\n",
    "    output_filter_params = filter_model(transformed_signal)\n",
    "\n",
    "    output_params = {**output_lfo_params, **output_filter_params, **output_fm_params}\n",
    "\n",
    "    denormalized_output_params = normalizer.denormalize(output_params)\n",
    "\n",
    "    denormalized_discrete_output_params = {cell_idx: {'operation': cell_params['operation'], 'parameters': discretize_params(cell_params['operation'], cell_params['parameters'], synth_cfg)}\n",
    "                                           for cell_idx, cell_params in denormalized_output_params.items()}\n",
    "\n",
    "    discrete_target_params = {cell_idx: {'operation': cell_params['operation'], 'parameters': discretize_params(cell_params['operation'][0], cell_params['parameters'], synth_cfg)}\n",
    "                              for cell_idx, cell_params in target_param_dict.items() if cell_params['operation'][0] != 'None'}\n",
    "\n",
    "    correct_preds = compare_params(discrete_target_params, denormalized_discrete_output_params)\n",
    "\n",
    "    for cell_idx, cell_data in correct_preds.items():\n",
    "        for param_name, correct_preds in cell_data.items():\n",
    "            results[f'{cell_idx}_{param_name}'] += correct_preds\n",
    "\n",
    "    n_samples += len(target_signal)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "for k, v in results.items():\n",
    "    results[k] = v / n_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "filter_model.train()\n",
    "ps = filter_model(transformed_signal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "p = ps[(0, 2)]['parameters']['filter_freq'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "p = torch.floor(p * 16000)\n",
    "p_s = p.squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "dude = torch.tensor(8.0, dtype=torch.float, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linspace(): argument 'steps' (position 3) must be int, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [59]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m p_lin \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinspace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdude\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: linspace(): argument 'steps' (position 3) must be int, not Tensor"
     ]
    }
   ],
   "source": [
    "p_lin = torch.linspace(0, 1, dude)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}