{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from dataset.ai_synth_dataset import AiSynthDataset\n",
    "from model.lit_module import LitModularSynth\n",
    "from utils.train_utils import get_project_root, to_numpy_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate a sound matching model\n",
    "\n",
    "In this notebook we are going over the steps to evaluate a sound matching model on a given test dataset.\n",
    "To see more about training such a model, see *train_model.ipynb*\n",
    "\n",
    "<br>\n",
    "\n",
    "Assumptions:\n",
    "1. The test data is generated by DiffMoog using the same preset as the one used for training the model (see *create_dataset.ipynb*)\n",
    "2. The resulting metrics will be the same as the ones reported during training. To add metrics edit *LitModularSynth._calculate_audio_metrics()*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "root = get_project_root()  # Verify correct project root or insert manually\n",
    "\n",
    "exp_name = \"basic_flow_example_experiment\"\n",
    "device = 'cuda:0'\n",
    "\n",
    "ckpt_name = r'epoch=1-step=80.ckpt'\n",
    "ckpt_path = root.joinpath('experiments', 'current', exp_name, 'checkpoints', ckpt_name)   # Path to the requested checkpoint\n",
    "\n",
    "synth_module = LitModularSynth.load_from_checkpoint(ckpt_path, device=device).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "val_data_dir = os.path.join(synth_module.cfg.data_dir, 'val')  # You can input a data directory manually instead\n",
    "\n",
    "val_dataset = AiSynthDataset(val_data_dir)\n",
    "dataloader = DataLoader(val_dataset, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from IPython.utils.io import capture_output\n",
    "import torch\n",
    "\n",
    "all_losses, all_metrics = [], []\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "\n",
    "    batch[0] = batch[0].to(device)\n",
    "\n",
    "    with torch.no_grad(), capture_output():\n",
    "        loss, step_losses, step_metrics, step_artifacts = synth_module.in_domain_step(batch, return_metrics=True)\n",
    "\n",
    "    all_losses.append(step_losses)\n",
    "    all_metrics.append(step_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses\n",
      "\traw_params_loss: 7.486570358276367\n",
      "\traw_spec_loss: 0.0\n",
      "\tweighted_params_loss: 7.486570358276367\n",
      "\tweighted_spec_loss: 0.0\n",
      "\tloss_total: 7.486570566892624\n",
      "************************************************\n",
      "\n",
      "Metrics\n",
      "\tpaper_lsd_value: 29.058761596679688\n",
      "\tlsd_value: 15.86365795135498\n",
      "\tpearson_stft: 0.08646538108587265\n",
      "\tpearson_fft: 0.05919661745429039\n",
      "\tmean_average_error: 1.5392720699310303\n",
      "\tmfcc_mae: 19.468284606933594\n",
      "\tspectral_convergence_value: 20.77668571472168\n",
      "************************************************\n"
     ]
    }
   ],
   "source": [
    "all_losses = {k: np.mean([to_numpy_recursive(dic[k]) for dic in all_losses]) for k in all_losses[0]}\n",
    "all_metrics = {k: np.mean([to_numpy_recursive(dic[k]) for dic in all_metrics]) for k in all_metrics[0]}\n",
    "\n",
    "for title, metrics_dict in zip(['Losses', 'Metrics'], [all_losses, all_metrics]):\n",
    "    print(f'\\n{title}:')\n",
    "    for metric_name, metric_val in metrics_dict.items():\n",
    "        print(f\"\\t{metric_name}: {metric_val}\")\n",
    "    print(\"************************************************\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}