{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noyuzrad/ai_synth/venv/lib/python3.8/site-packages/torchaudio/functional/functional.py:539: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (513) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import helper\n",
    "from model.model import SimpleSynthNetwork\n",
    "from config import SynthConfig, Config, DatasetConfig\n",
    "from dataset.ai_synth_dataset import AiSynthDataset, NSynthDataset, create_data_loader\n",
    "from synth.synth_architecture import SynthModular, SynthModularCell\n",
    "from run_scripts.inference.inference import visualize_signal_prediction\n",
    "from run_scripts.train_helper import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_to_visualize = 'modular_synth50k'\n",
    "\n",
    "cfg = Config()\n",
    "synth_cfg = SynthConfig()\n",
    "dataset_cfg = DatasetConfig(dataset_to_visualize)\n",
    "\n",
    "device = 'cuda:0'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noyuzrad/ai_synth/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/noyuzrad/ai_synth/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "SimpleSynthNetwork(\n  (backbone): ResNet(\n    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=128, bias=True)\n  )\n  (heads_module_dict): ModuleDict(\n    ((0, 0)_lfo_sine_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((0, 0)_lfo_sine_freq): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((1, 1)_fm_lfo_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((1, 1)_fm_lfo_fm_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((1, 1)_fm_lfo_freq_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((1, 1)_fm_lfo_waveform): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=3, bias=False)\n      )\n    )\n    ((1, 1)_fm_lfo_mod_index): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 2)_fm_sine_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((0, 2)_fm_sine_fm_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((0, 2)_fm_sine_amp_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 2)_fm_sine_freq_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 2)_fm_sine_mod_index): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((1, 2)_fm_saw_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((1, 2)_fm_saw_fm_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((1, 2)_fm_saw_amp_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((1, 2)_fm_saw_freq_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((1, 2)_fm_saw_mod_index): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((2, 2)_fm_square_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((2, 2)_fm_square_fm_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n    ((2, 2)_fm_square_amp_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((2, 2)_fm_square_freq_c): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((2, 2)_fm_square_mod_index): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 4)_env_adsr_attack_t): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 4)_env_adsr_decay_t): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 4)_env_adsr_sustain_t): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 4)_env_adsr_sustain_level): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 4)_env_adsr_release_t): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 5)_lowpass_filter_filter_freq): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 5)_lowpass_filter_resonance): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 6)_tremolo_amount): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=1, bias=False)\n      )\n    )\n    ((0, 6)_tremolo_active): MLPBlock(\n      (mlp): Sequential(\n        (0): Linear(in_features=128, out_features=64, bias=False)\n        (1): ReLU()\n        (2): Linear(in_features=64, out_features=10, bias=False)\n        (3): ReLU()\n        (4): Linear(in_features=10, out_features=2, bias=False)\n      )\n    )\n  )\n  (softmax): Softmax(dim=1)\n  (sigmoid): Sigmoid()\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ckpt = r'/home/almogelharar/almog/ai_synth/experiments/current/modular_synth_120e/ckpts/trained_synth_net.pt'\n",
    "model = SimpleSynthNetwork('MODULAR', synth_cfg, cfg, device, backbone='resnet').to(device)\n",
    "model.load_state_dict(torch.load(model_ckpt))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSynth dataloader found 4992 wav files in /home/almogelharar/almog/ai_synth/data/modular_synth50k/val/wav_files/\n"
     ]
    }
   ],
   "source": [
    "cwd = r'/home/almogelharar/almog/ai_synth/'\n",
    "split_to_visualize = 'val'\n",
    "data_dir = os.path.join(cwd, 'data', dataset_to_visualize, split_to_visualize, '')\n",
    "\n",
    "wav_files_dir = os.path.join(data_dir, 'wav_files', '')\n",
    "params_csv_path = os.path.join(data_dir, 'params_dataset.pkl')\n",
    "\n",
    "ai_synth_dataset = AiSynthDataset(params_csv_path, wav_files_dir, device)\n",
    "test_dataloader = create_data_loader(ai_synth_dataset, 32, 4, shuffle=False)\n",
    "\n",
    "wav_files_dir = os.path.join(data_dir, 'wav_files', '')\n",
    "\n",
    "split_to_visualize = 'val_nsynth'\n",
    "data_dir = os.path.join('data', dataset_to_visualize, split_to_visualize, '')\n",
    "\n",
    "nsynth_dataset = NSynthDataset(wav_files_dir, device)\n",
    "nsynth_dataloader = create_data_loader(nsynth_dataset, 32, 4, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "synth_cfg = SynthConfig()\n",
    "cfg = Config()\n",
    "\n",
    "transform = helper.mel_spectrogram_transform(cfg.sample_rate).to(device)\n",
    "normalizer = helper.Normalizer(cfg.signal_duration_sec, synth_cfg)\n",
    "\n",
    "modular_synth = SynthModular(synth_cfg=synth_cfg,\n",
    "                             sample_rate=cfg.sample_rate,\n",
    "                             signal_duration_sec=cfg.signal_duration_sec,\n",
    "                             num_sounds_=1,\n",
    "                             device=device,\n",
    "                             preset='MODULAR')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def infer_and_compare(signals, target_params_dic, signals_indices):\n",
    "    signals = helper.move_to(signals, device)\n",
    "    normalizer = helper.Normalizer(cfg.signal_duration_sec, synth_cfg)\n",
    "\n",
    "    transformed_signal = transform(signals)\n",
    "\n",
    "    output_dic = model(transformed_signal)\n",
    "\n",
    "    # Infer predictions\n",
    "    denormalized_output_dict = normalizer.denormalize(output_dic)\n",
    "    predicted_param_dict = helper.clamp_regression_params(denormalized_output_dict, synth_cfg, cfg)\n",
    "\n",
    "    update_params = []\n",
    "    for index, operation_dict in predicted_param_dict.items():\n",
    "        synth_modular_cell = SynthModularCell(index=index, parameters=operation_dict['params'])\n",
    "        update_params.append(synth_modular_cell)\n",
    "\n",
    "    modular_synth.update_cells(update_params)\n",
    "    modular_synth.generate_signal(num_sounds_=len(transformed_signal))\n",
    "\n",
    "    # for i in range(len(signals)):\n",
    "    for i in range(5):\n",
    "\n",
    "        sample_params_orig, sample_params_pred = parse_synth_params(target_params_dic, predicted_param_dict, i)\n",
    "        signal_index = signals_indices[i]\n",
    "\n",
    "        orig_audio = signals[i]\n",
    "        pred_audio = modular_synth.signal[i]\n",
    "        orig_audio_np = orig_audio.detach().cpu().numpy()\n",
    "        pred_audio_np = pred_audio.detach().cpu().numpy()\n",
    "\n",
    "        orig_audio_transformed = librosa.feature.melspectrogram(y=orig_audio_np,\n",
    "                                                                sr=cfg.sample_rate,\n",
    "                                                                n_fft=1024,\n",
    "                                                                hop_length=512,\n",
    "                                                                n_mels=64)\n",
    "        orig_audio_transformed_db = librosa.power_to_db(orig_audio_transformed, ref=np.max)\n",
    "        pred_audio_transformed = librosa.feature.melspectrogram(y=pred_audio_np,\n",
    "                                                                sr=cfg.sample_rate,\n",
    "                                                                n_fft=1024,\n",
    "                                                                hop_length=512,\n",
    "                                                                n_mels=64)\n",
    "        pred_audio_transformed_db = librosa.power_to_db(pred_audio_transformed, ref=np.max)\n",
    "\n",
    "        # plot original vs predicted signal\n",
    "        plt.figure(figsize=[30, 20])\n",
    "        plt.ion()\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.title(f\"original audio\")\n",
    "        plt.ylim([-1, 1])\n",
    "        plt.plot(orig_audio_np)\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.ylim([-1, 1])\n",
    "        plt.title(\"predicted audio\")\n",
    "        plt.plot(pred_audio_np)\n",
    "        plt.subplot(2, 2, 3)\n",
    "        librosa.display.specshow(orig_audio_transformed_db, sr=cfg.sample_rate, hop_length=512,\n",
    "                                 x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.subplot(2, 2, 4)\n",
    "        librosa.display.specshow(pred_audio_transformed_db, sr=cfg.sample_rate, hop_length=512,\n",
    "                                 x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.ioff()\n",
    "        plots_path = dataset_cfg.inference_plots_dir.joinpath(f\"sound{signal_index}_plots.png\")\n",
    "        plt.savefig(plots_path)\n",
    "\n",
    "        signal_vis = visualize_signal_prediction(orig_audio[i], pred_audio[i], sample_params_orig, sample_params_pred, db=True)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 33227, 33267, 33307, 33347) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1163\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1163\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/queues.py:116\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# unserialize the data after having released the lock\u001B[39;00m\n\u001B[0;32m--> 116\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ForkingPickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py:297\u001B[0m, in \u001B[0;36mrebuild_storage_fd\u001B[0;34m(cls, df, size)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrebuild_storage_fd\u001B[39m(\u001B[38;5;28mcls\u001B[39m, df, size):\n\u001B[0;32m--> 297\u001B[0m     fd \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/resource_sharer.py:57\u001B[0m, in \u001B[0;36mDupFd.detach\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m'''Get the fd.  This should only be called once.'''\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_resource_sharer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_id\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m conn:\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m reduction\u001B[38;5;241m.\u001B[39mrecv_handle(conn)\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/resource_sharer.py:87\u001B[0m, in \u001B[0;36m_ResourceSharer.get_connection\u001B[0;34m(ident)\u001B[0m\n\u001B[1;32m     86\u001B[0m address, key \u001B[38;5;241m=\u001B[39m ident\n\u001B[0;32m---> 87\u001B[0m c \u001B[38;5;241m=\u001B[39m \u001B[43mClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43maddress\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauthkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_process\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauthkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m c\u001B[38;5;241m.\u001B[39msend((key, os\u001B[38;5;241m.\u001B[39mgetpid()))\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/connection.py:502\u001B[0m, in \u001B[0;36mClient\u001B[0;34m(address, family, authkey)\u001B[0m\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 502\u001B[0m     c \u001B[38;5;241m=\u001B[39m \u001B[43mSocketClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m authkey \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(authkey, \u001B[38;5;28mbytes\u001B[39m):\n",
      "File \u001B[0;32m/usr/lib/python3.8/multiprocessing/connection.py:630\u001B[0m, in \u001B[0;36mSocketClient\u001B[0;34m(address)\u001B[0m\n\u001B[1;32m    629\u001B[0m s\u001B[38;5;241m.\u001B[39msetblocking(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 630\u001B[0m \u001B[43ms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43maddress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Connection(s\u001B[38;5;241m.\u001B[39mdetach())\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m signals, target_params_dic, signals_indices \u001B[38;5;129;01min\u001B[39;00m test_dataloader:\n\u001B[1;32m      2\u001B[0m     infer_and_compare(signals, target_params_dic, signals_indices)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m signals, target_params_dic, signals_indices \u001B[38;5;129;01min\u001B[39;00m nsynth_dataloader:\n",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:441\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    439\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_iterator()\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 441\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1142\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._reset\u001B[0;34m(self, loader, first_iter)\u001B[0m\n\u001B[1;32m   1140\u001B[0m resume_iteration_cnt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m resume_iteration_cnt \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1142\u001B[0m     return_idx, return_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(return_idx, _utils\u001B[38;5;241m.\u001B[39mworker\u001B[38;5;241m.\u001B[39m_ResumeIteration):\n\u001B[1;32m   1144\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m return_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1325\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1322\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1323\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1324\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1325\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1326\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1327\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/ai_synth/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1176\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1175\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(pids_str)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1178\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 33227, 33267, 33307, 33347) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "for signals, target_params_dic, signals_indices in test_dataloader:\n",
    "    infer_and_compare(signals, target_params_dic, signals_indices)\n",
    "\n",
    "for signals, target_params_dic, signals_indices in nsynth_dataloader:\n",
    "    infer_and_compare(signals, target_params_dic, signals_indices)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}